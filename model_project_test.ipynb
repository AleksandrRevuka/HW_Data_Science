{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 14:28:42.248937: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-10 14:28:42.251354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-10 14:28:42.319308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-10 14:28:42.433083: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-10 14:28:43.583203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import urllib.request\n",
    "\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 14:28:44.808702: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-10 14:28:44.942601: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-10 14:28:44.942782: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-10 14:28:44.943450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-10 14:28:44.943592: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-10 14:28:44.943729: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-10 14:28:45.066748: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-10 14:28:45.071307: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-10 14:28:45.071506: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-10 14:28:45.072104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 104 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/alex/Python_projects/HW_Data_Science/models/model_filter_drop_vgg16.h5\"\n",
    "loaded_model = load_model(path)\n",
    "\n",
    "# loaded_model.summary()\n",
    "# visualkeras.layered_view(model_filter, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.usatoday.com/gcdn/authoring/authoring-images/2023/12/08/USAT/71852301007-1569872652.jpg\"\n",
    "resp = urllib.request.urlopen(url)\n",
    "image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Convert the image from BGR to RGB\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize it to 32x32 pixels\n",
    "image = cv2.resize(image, (32,32))\n",
    "\n",
    "# Normalize the image\n",
    "image = image.astype('float32')/255.\n",
    "\n",
    "# Add an extra dimension because the model expects a batch of images\n",
    "image = image.reshape((1, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 14:28:46.858860: I external/local_xla/xla/service/service.cc:168] XLA service 0x72d1af0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-10 14:28:46.860053: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "2024-02-10 14:28:46.895929: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-10 14:28:47.039260: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-02-10 14:28:47.251549: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-10 14:28:47.306517: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-10 14:28:47.309647: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.24 = (f32[1,32,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,32,32]{3,2,1,0} %transpose.10, f32[32,3,3,3]{3,2,1,0} %transpose.11, f32[32]{0} %arg2.3), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1160}, backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16908288 bytes.\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_19338/2647221604.py\", line 1, in <module>\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 118, in error_handler\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 511, in predict\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 212, in one_step_on_data_distributed\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.24 = (f32[1,32,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,32,32]{3,2,1,0} %transpose.10, f32[32,3,3,3]{3,2,1,0} %transpose.11, f32[32]{0} %arg2.3), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1160}, backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16908288 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_1016]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_19338/2647221604.py\", line 1, in <module>\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 118, in error_handler\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 511, in predict\n\n  File \"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 212, in one_step_on_data_distributed\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.24 = (f32[1,32,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,32,32]{3,2,1,0} %transpose.10, f32[32,3,3,3]{3,2,1,0} %transpose.11, f32[32]{0} %arg2.3), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/alex/Python_projects/HW_Data_Science/.conda/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1160}, backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16908288 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_1016]"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = prediction.argmax()\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print('Predicted class: ', class_names[predicted_class])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
